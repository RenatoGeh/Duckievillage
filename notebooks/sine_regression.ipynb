{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V00rkAAMNgYR"
   },
   "source": [
    "# Approximating the sine function with a neural network regressor\n",
    "\n",
    "MAC0318 - Introduction to Mobile Robot Programming\n",
    "\n",
    "EP7 - Sine regression\n",
    "\n",
    "---\n",
    "\n",
    "## Task\n",
    "\n",
    "In this assignment, you will train a neural network that approximates the sine function in the interval $-\\pi,\\pi$. You will need to generate a noisy sample of the function, build a neural network to approximate and then evaluate the network on an independently generated test set. You should evaluate configurations of architectures (no. of hidden layer, no. of nodes in each layer, optimization algorithm, etc). You should also test with different amounts of training data and noise. The output of your  final network (the one with the high-scoring architecture, optimization algorithm, etc) should be visually similar to the sine function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all requisites\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training dataset\n",
    "\n",
    "Generate a dataset of `N=num_samples` points $(x,\\sin(x)+\\epsilon)$ where $\\epsilon$ is drawn from a Gaussian distribution with zero mean and variance $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEJCtaaoSWtZ"
   },
   "outputs": [],
   "source": [
    "# Generate a dataset, where each data point is a tuple (x, sin(x)+noise).\n",
    "def generate_dataset(num_samples, sigma):\n",
    "    x = np.linspace(-np.pi,np.pi,num_samples)\n",
    "    y = np.sin(x)+np.random.normal(0, sigma, num_samples)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HNFjgCvSnhQ"
   },
   "source": [
    "The best way to test the generated dataset is to visually inspect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzmgT9RsSwO6"
   },
   "outputs": [],
   "source": [
    "# Plots data points from dataset D.\n",
    "def plot_dataset(x, y):\n",
    "    plt.scatter(x, y, marker='o', c='r')\n",
    "    xx = np.linspace(-np.pi,np.pi,1000)\n",
    "    plt.plot(xx, np.sin(xx), c='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKAmPsZXS8XK"
   },
   "source": [
    "---\n",
    "\n",
    "## Creating our model\n",
    "\n",
    "Now create a neural network to approximate the sine function. Try different architectures (e.g. vary number of layers, number of perceptrons per layer, optimizer, objective function, etc.) and see which works best given our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0CBq699S-y0"
   },
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    model = keras.Sequential([\n",
    "      # Experiment with the number of layers and number of perceptrons per layer.\n",
    "      layers.Dense(1, input_dim=1, activation=tf.nn.relu),\n",
    "      layers.Dense(1) # Output layer.\n",
    "    ])\n",
    "    \n",
    "    # alternative optimization algorithm\n",
    "    #my_optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    \n",
    "    # Experiment with the loss function, optimizer and metrics.\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics= ['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xgRXZnoTgiG"
   },
   "source": [
    "### Training\n",
    "\n",
    "Now train your network. Don't forget to set a percentage of the dataset for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlbEmQNFT1JV"
   },
   "outputs": [],
   "source": [
    "# Display training progress by printing a single dot for each completed epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "\n",
    "# Trains model\n",
    "def train(x, y, model, num_epochs):\n",
    "    return model.fit( x, y,\n",
    "                         epochs=num_epochs, \n",
    "                         validation_split = 0.0,  # for small datasets we don't use validation set \n",
    "                         verbose=0,\n",
    "                         callbacks=[PrintDot()]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sroyXy39UBcZ"
   },
   "source": [
    "Once we have our function approximator, we need to find a way to plot our data points overlayed with the approximated function. We'll do this through the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpBLesJhUm_l"
   },
   "outputs": [],
   "source": [
    "# Plots dataset overlayed with model's approximated function curve.\n",
    "def plot_model(x, y, model):\n",
    "    plt.figure()\n",
    "    plt.xlabel('x')\n",
    "    plt.scatter(x, y, marker='o', c='r', label='Train data')\n",
    "    xx = np.linspace(-np.pi,np.pi,1000)\n",
    "    plt.plot(xx, np.sin(xx), c='b', label='Sin')\n",
    "    plt.plot(xx, model.predict(xx), c='g', label='Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #plt.savefig(\"net.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVuAoIZCUBU8"
   },
   "source": [
    "---\n",
    "\n",
    "## Results\n",
    "\n",
    "With everything properly defined and implemented, let's generate our dataset, plot our dataset, create our model, train it and finally plot the approximated curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGOOldHnUy7q"
   },
   "outputs": [],
   "source": [
    "# generate and show dataset\n",
    "num_samples, variance = ?, ?\n",
    "x,y = generate_dataset(num_samples,variance)\n",
    "plot_dataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model and show summary\n",
    "net = generate_model()\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "num_epochs = ?\n",
    "history = train(x, y, net, num_epocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.plot(history.epoch, history.history['mean_squared_error'],\n",
    "           label='Train Error')\n",
    "# uncomment if you set a validation set\n",
    "# plt.plot(history.epoch, history.history['val_mean_squared_error'],\n",
    "#            label='Validation Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display network predictions\n",
    "plot_model(x, y, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluate your network\n",
    "\n",
    "Before we claim to the world that we have approximated the sine function, we need to generate a test dataset with different noise parameters so we can properly evaluate whether our trained model is robust. Generate a new dataset $T$ with different noise parameters, and plot the prediction curve of the learned model in this new setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test dataset.\n",
    "T = None\n",
    "# Plot N's curve on T's data points.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "regression_mac0318_2019.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
